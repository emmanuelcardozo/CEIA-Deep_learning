{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9_1a5iymIvC"
   },
   "source": [
    "   <img src=\"..\\TP4_CNN\\img\\img.png\" width=\"500\" align=\"right\">\n",
    "\n",
    "# Deep Learning\n",
    "\n",
    "### Alumno: Emmanuel Cardozo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. EJERCICIO\n",
    "\n",
    "Vamos a armar una pequeña competición en el curso.\n",
    "El objetivo es armar una arquitectura de CNN que identifique el dataset MNIST.\n",
    "Se van a usar capas de convolución, de activación y de pooling a elección. Cada alumno eligirá su modelo y los respectivos hiperparámetros, lo entrenará y presentará los siguientes resultados:\n",
    "\n",
    "*   `test_acc` (del test final)\n",
    "*   `n_parameter`\n",
    "*   `n_layers` (conv + activacion + pooling = 1 capa)\n",
    "*   `n_epochs` de entrenamiento usadas.\n",
    "\n",
    "\n",
    "El modelo se deberá ajustar a los siguientes parámetros:\n",
    "\n",
    "*   train: 80%, validation: 10%, test: 10% (los datos serán dados así todos usan el mismo set para cada grupo. Están en el github el curso).\n",
    "*   capa final de salida será una softmax de 10 elementos.\n",
    "*   loss_function será `CrossEntropyLoss`.\n",
    "\n",
    "El ganador de la competencia será aquel que consiga el mayor `score` empleando la siguietne fórmula:\n",
    "\n",
    "$$ score = \\frac{1}{log_{10}(n\\_parameter)} * \\frac{10}{n\\_epochs}*test\\_acc*n\\_layers$$\n",
    "\n",
    "Deberan presentar su código colab funcionando y el score alcanzado (con los valores de cada variable que compone el score).\n",
    "\n",
    "Es una competencia fairplay y con fines didácticos, esta formula del ```score``` fué inventada.... no usar como referencia para definir qué modelo utilizar.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wIQ8hjDpdVi"
   },
   "source": [
    "#### Importar lo necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uHQUjDs12DLW"
   },
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeJy8fjPn4wi"
   },
   "source": [
    "#### configuramos el `device` acorde al device disponible\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lOV9xybtn4I3"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nQ-MLk6Do8e"
   },
   "source": [
    "1. Cargar base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"/tf/notebooks/CEIA-deep_learning/clase_5/data\"\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "def custom_dataloader(data_file, label_file, batch_size=512):\n",
    "    data = np.load(os.path.join(basepath, data_file), allow_pickle=True)\n",
    "    data = np.expand_dims(data, axis=1)\n",
    "    labels = np.load(os.path.join(basepath, label_file), allow_pickle=True)\n",
    "    dataset = CustomDataset(data, labels)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "dataloader = {\n",
    "    \"train\": custom_dataloader(\"train.pkl\", \"train_label.pkl\"),\n",
    "    \"val\": custom_dataloader(\"val.pkl\", \"val_label.pkl\"),\n",
    "    \"test\": custom_dataloader(\"test.pkl\", \"test_label.pkl\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oikthAE4Dteb"
   },
   "source": [
    "2. Ver que la base de datos esté OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyq2UFIl-Qjy",
    "outputId": "ed7a0a94-d5e7-4ae4-b111-118f9805fae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataloader))\n",
    "print(type(dataloader[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "p2fs6Qdivs1H",
    "outputId": "6cfc7823-33d2-4c0d-b0e5-907d4727d227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([512, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([512])\n",
      "tamaño de 1 imagen:  torch.Size([1, 28, 28])\n",
      "tamaño 1 imagen DESPUES de squeeze:  torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Display image and label from dataloader (dataloader -> una herramienta para hacer batches de datasets)\n",
    "train_features, train_labels = next(iter(dataloader[\"train\"]))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0]\n",
    "print(\"tamaño de 1 imagen: \", img.shape)\n",
    "# le QUITO 1 dimension (la del tamaño del batch) para poder graficar\n",
    "img = train_features[0].squeeze()\n",
    "print(\"tamaño 1 imagen DESPUES de squeeze: \", img.shape)\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY0TN4erDxRd"
   },
   "source": [
    "3. Construyo mi CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(c_in, c_out, k=3, p=1, s=1, pk=1, ps=1, pp=0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(pk, stride=ps, padding=pp),\n",
    "    )\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = conv_block(\n",
    "            c_in=1, c_out=32, k=7, p=\"same\", s=1, pk=2, ps=2, pp=0\n",
    "        )\n",
    "        self.conv_block2 = conv_block(\n",
    "            c_in=32, c_out=64, k=5, p=\"same\", s=1, pk=1, ps=1, pp=0\n",
    "        )\n",
    "        self.conv_block3 = conv_block(\n",
    "            c_in=64, c_out=128, k=3, p=\"same\", s=1, pk=1, ps=1, pp=0\n",
    "        )\n",
    "        self.conv_block4 = conv_block(\n",
    "            c_in=128, c_out=256, k=3, p=\"same\", s=1, pk=2, ps=2, pp=0\n",
    "        )\n",
    "        self.conv_block5 = conv_block(\n",
    "            c_in=256, c_out=512, k=3, p=\"same\", s=1, pk=1, ps=1, pp=0\n",
    "        )\n",
    "        self.conv_block6 = conv_block(\n",
    "            c_in=512, c_out=1024, k=3, p=\"same\", s=1, pk=1, ps=1, pp=0\n",
    "        )\n",
    "        self.conv_block7 = conv_block(\n",
    "            c_in=1024, c_out=512, k=3, p=\"same\", s=1, pk=2, ps=2, pp=0\n",
    "        )\n",
    "        self.conv_block8 = conv_block(\n",
    "            c_in=512, c_out=256, k=3, p=\"same\", s=1, pk=1, ps=1, pp=0\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(in_features=2304, out_features=1024)\n",
    "        self.linear2 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.linear3 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.linear4 = nn.Linear(in_features=256, out_features=10)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv_block1(input)\n",
    "        out = self.conv_block2(out)\n",
    "        out = self.conv_block3(out)\n",
    "        out = self.conv_block4(out)\n",
    "        out = self.conv_block5(out)\n",
    "        out = self.conv_block6(out)\n",
    "        out = self.conv_block7(out)\n",
    "        out = self.conv_block8(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.linear4(out)\n",
    "        return out\n",
    "\n",
    "    def fit(self, dataloader, epochs=10, lr=1e-3):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        final_loss = 0\n",
    "        final_acc = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            train_loss, train_acc = [], []\n",
    "            bar = tqdm(dataloader[\"train\"])\n",
    "            for batch in bar:\n",
    "                X, y = batch\n",
    "                X, y = X.to(device).float(), y.to(device).long()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(X)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss.append(loss.item())\n",
    "                acc = (y == torch.argmax(y_pred, axis=1)).sum().item() / len(y)\n",
    "                train_acc.append(acc)\n",
    "                bar.set_description(\n",
    "                    f\"Epoch {epoch+1}/{epochs}:\\tloss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\"\n",
    "                )\n",
    "\n",
    "            self.eval()\n",
    "            test_loss, test_acc = [], []\n",
    "            bar = tqdm(dataloader[\"test\"])\n",
    "            with torch.no_grad():\n",
    "                for batch in bar:\n",
    "                    X, y = batch\n",
    "                    X, y = X.to(device).float(), y.to(device).long()\n",
    "                    y_pred = model(X)\n",
    "                    loss = criterion(y_pred, y)\n",
    "                    test_loss.append(loss.item())\n",
    "                    acc = (y == torch.argmax(y_pred, axis=1)).sum().item() / len(y)\n",
    "                    test_acc.append(acc)\n",
    "                    bar.set_description(\n",
    "                        f\"\\t\\ttest_loss {np.mean(test_loss):.5f} test_acc {np.mean(test_acc):.5f}\"\n",
    "                    )\n",
    "                    final_loss = np.mean(test_loss)\n",
    "                    final_acc = np.mean(test_acc)\n",
    "\n",
    "        return final_loss, final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]           1,600\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 64, 14, 14]          51,264\n",
      "              ReLU-5           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-6           [-1, 64, 14, 14]               0\n",
      "            Conv2d-7          [-1, 128, 14, 14]          73,856\n",
      "              ReLU-8          [-1, 128, 14, 14]               0\n",
      "         MaxPool2d-9          [-1, 128, 14, 14]               0\n",
      "           Conv2d-10          [-1, 256, 14, 14]         295,168\n",
      "             ReLU-11          [-1, 256, 14, 14]               0\n",
      "        MaxPool2d-12            [-1, 256, 7, 7]               0\n",
      "           Conv2d-13            [-1, 512, 7, 7]       1,180,160\n",
      "             ReLU-14            [-1, 512, 7, 7]               0\n",
      "        MaxPool2d-15            [-1, 512, 7, 7]               0\n",
      "           Conv2d-16           [-1, 1024, 7, 7]       4,719,616\n",
      "             ReLU-17           [-1, 1024, 7, 7]               0\n",
      "        MaxPool2d-18           [-1, 1024, 7, 7]               0\n",
      "           Conv2d-19            [-1, 512, 7, 7]       4,719,104\n",
      "             ReLU-20            [-1, 512, 7, 7]               0\n",
      "        MaxPool2d-21            [-1, 512, 3, 3]               0\n",
      "           Conv2d-22            [-1, 256, 3, 3]       1,179,904\n",
      "             ReLU-23            [-1, 256, 3, 3]               0\n",
      "        MaxPool2d-24            [-1, 256, 3, 3]               0\n",
      "          Flatten-25                 [-1, 2304]               0\n",
      "           Linear-26                 [-1, 1024]       2,360,320\n",
      "           Linear-27                  [-1, 512]         524,800\n",
      "           Linear-28                  [-1, 256]         131,328\n",
      "           Linear-29                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 15,239,690\n",
      "Trainable params: 15,239,690\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.38\n",
      "Params size (MB): 58.13\n",
      "Estimated Total Size (MB): 62.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:\tloss 1.58484 acc 0.54883: 100% 110/110 [00:15<00:00,  6.90it/s]\n",
      "\t\ttest_loss 0.13188 test_acc 0.95713: 100% 14/14 [00:00<00:00, 24.00it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "test_loss, test_acc = model.fit(dataloader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aQ5n86Kwk7B"
   },
   "source": [
    "# Score Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score contando cada conv_block como una layer: 17.322\n",
      "Score contando todos los bloques: 51.967\n"
     ]
    }
   ],
   "source": [
    "# Si cada bloque conv2d, activation, maxpooling se considera como una layer\n",
    "n_params = 15239690\n",
    "n_layers = 13\n",
    "score = (1 / math.log10(n_params)) * (10 / epochs) * test_acc * n_layers\n",
    "print(f\"Score contando cada conv_block como una layer: {score:.3f}\")\n",
    "\n",
    "# Considerando todos los sub bloques como layers\n",
    "n_layers = 13 * 3\n",
    "score = (1 / math.log10(n_params)) * (10 / epochs) * test_acc * n_layers\n",
    "print(f\"Score contando todos los bloques: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_TP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
